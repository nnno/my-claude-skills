---
name: deep-research
description: >
  トピックについて深いリサーチを実行し、構造化されたMarkdownレポートを生成する。
  WebSearch/WebFetchで20〜50クエリを並列実行し、複数情報源のクロスチェックを行う。
  「リサーチして」「調査して」「deep research」「詳しく調べて」「技術調査」「比較調査」
  「〜について調べて」「市場調査」「トレンド調査」と依頼された時に使用する。
  Also triggers for "research this", "investigate", "deep dive into",
  "survey", "literature review", "technical investigation".
  単純な質問への回答、コードの実装、既知の事実の確認には使用しない。
---

# Deep Research

トピックについてWebSearch/WebFetchを活用した多角的リサーチを実行し、構造化されたMarkdownレポートを生成する。

## ワークフロー

### Phase 1: トピック受け取り

1. スキルの引数からリサーチトピックを取得する
2. 引数が空の場合、ユーザーにトピックを尋ねる
3. 出力ファイルパスを決定する:
   - 引数で `<topic> --output <path>` のように指定があればそのパスを使用
   - 未指定の場合、カレントディレクトリに `research-report-YYYY-MM-DD-<topic-slug>.md` を生成

### Phase 2: スコープ明確化

`AskUserQuestion` で以下を確認する:

**質問1: リサーチの深さ**
- 概要レベル（主要ポイントの把握、10〜15クエリ）
- 標準（バランスの取れた調査、20〜30クエリ）
- 詳細（網羅的な調査、40〜50クエリ）

**質問2: フォーカスと制約**
- 時間軸の制約（最新情報のみ / 過去N年 / 制限なし）
- 特に重視する観点や除外したい領域
- 特定の情報源の優先・排除

**質問3: 批判的レビュー**
- 有効にする（レポート生成後に批判的レビューフェーズを実行する）
- スキップする（Recommended）（レポート生成後すぐにサマリーを提示する）

ユーザーの回答に基づき、リサーチクエリのリストと担当分野の分割案を作成する。

### Phase 3: リサーチ実行

Taskツールで **sonnet** モデルの subagent を3〜5個並列起動し、テーマ別に検索を分担する。

各subagentの設定:
- `subagent_type: "general-purpose"`
- `model: "sonnet"`
- 担当する検索クエリ群とフォーカス領域を明示的にプロンプトに含める

各subagentへの指示内容:
- 割り当てられたクエリをWebSearchで実行する
- 有望な検索結果のURLをWebFetchで取得し、詳細を確認する
- 情報源ごとに以下の形式で記録する:
  ```
  - **S-{連番}**: {タイトル}
    - URL: {URL}
    - 公開日: {YYYY-MM-DD or 不明}
    - 種別: {公式ドキュメント/学術論文/企業ブログ/個人ブログ/ニュース記事/フォーラム/SNS}
    - 主張: {このソースが述べている主要な主張を1〜3文で}
    - 関連トピック: {このソースがカバーするサブトピックのリスト}
  ```
- 矛盾する情報がある場合は両方記載し、どちらがより信頼できるか理由とともに報告する
- 最終的に、担当領域の調査結果を上記の形式で構造化して返す

GitHub MCP（`gh` コマンド）が利用可能な環境では、追加のsubagentを起動してリポジトリ・Issue・ディスカッションも調査する。利用不可の場合はスキップする。

すべてのsubagentの結果が返ってきたら、次のPhaseでEvidence Tableに統合する。

### Phase 4: Evidence Table構築

すべてのsubagentから返ってきたソース情報を統合し、Evidence Tableを構築する。

1. **重複排除**: 同一URLのソースをマージし、異なるsubagentからの主張を統合する
2. **信頼性スコアリング**: 各ソースに信頼性ティアを付与する:
   - **A（高信頼）**: 公式ドキュメント、学術論文（査読済）、政府・国際機関の発表
   - **B（標準）**: 企業ブログ、ニュース記事（大手メディア）、技術カンファレンス資料
   - **C（参考）**: 個人ブログ、フォーラム、SNS、公開日不明の記事
3. **クロスチェック**: 複数ソースで裏付けられている主張と、単一ソースのみの主張を区別する
4. **カバレッジマップ**: リサーチクエリごとにどのソースがカバーしているかを整理し、ギャップを特定する

Evidence Tableの形式:
```markdown
| ID | タイトル | 種別 | 公開日 | ティア | 裏付け数 | 関連トピック |
|----|---------|------|--------|--------|---------|-------------|
| S-01 | ... | 公式ドキュメント | 2025-01-15 | A | 3 | topic1, topic2 |
| S-02 | ... | 企業ブログ | 2024-11-20 | B | 1 | topic2 |
```

- カバレッジにギャップがある場合、追加の検索クエリを実行して補完する（最大5クエリ）
- Evidence TableをWriteツールで `{出力ディレクトリ}/evidence-table-YYYY-MM-DD-<topic-slug>.md` に保存する

### Phase 5: レポート生成

Taskツールで **opus** モデルの subagent を起動する。

subagentの設定:
- `subagent_type: "general-purpose"`
- `model: "opus"`

subagentへの指示内容:
- Phase 4で構築したEvidence Tableと、Phase 3で収集した各ソースの詳細をプロンプトに含める
- `references/report-template.md` のテンプレート構造に従いレポートを生成する
- 以下の原則を遵守する:
  - ティアAのソースを優先して引用する。ティアCのみで裏付けられる主張にはその旨を注記する
  - 複数ソースで裏付けられた主張（裏付け数2以上）を優先的に取り上げる
  - 事実と意見・推測を明確に区別する
  - 矛盾する情報がある場合は両方記載し、各ソースのティアを踏まえて分析を加える
  - 情報の公開日を可能な限り明記する
- インライン引用は `[S-{ID}]` 形式で本文中に挿入し、セクション末の参照リストでURLとリンクする
- リンクは `<a href="URL" target="_blank">テキスト</a>` 形式で記述する
- 生成したレポートをWriteツールで出力ファイルパスに保存する

### Phase 6: 批判的レビュー（オプション）

Phase 2で批判的レビューが有効にされた場合のみ実行する。スキップが選択された場合はPhase 7に進む。

Taskツールで **sonnet** モデルの subagent を起動する。

subagentの設定:
- `subagent_type: "general-purpose"`
- `model: "sonnet"`

subagentへの指示内容:
- Phase 5で生成されたレポートの全文とPhase 4のEvidence Tableをプロンプトに含める
- 以下の観点でレポートを批判的にレビューする:
  - **根拠の妥当性**: 主張に対してソースが適切に引用されているか。引用元の信頼性は十分か
  - **論理の一貫性**: 論理的な飛躍や矛盾がないか。前提と結論が整合しているか
  - **カバレッジの偏り**: 特定の視点や立場に偏っていないか。反対意見や代替的な見解が欠落していないか
  - **情報の鮮度**: 古い情報に基づく主張が、現在も有効であるか
  - **過度の一般化**: 限定的なエビデンスから広範な結論を導いていないか
- レビュー結果を以下の形式で返す:
  - 指摘事項のリスト（重要度: 高/中/低）
  - 各指摘に対する修正提案
  - レポート全体の信頼性評価（A: 高い / B: 概ね信頼できる / C: 注意が必要）

レビュー結果に重要度「高」の指摘がある場合:
1. 指摘内容と修正提案をユーザーに提示する
2. 修正を反映するか確認する
3. ユーザーが修正を承認した場合、レポートに修正を反映する

レビュー結果はレポート末尾に「レビューノート」セクションとして追記する:
```markdown
---
## レビューノート

> このレポートは批判的レビューを経ています。信頼性評価: {A/B/C}

{重要度「中」以上の指摘事項と対応の要約}
```

### Phase 7: サマリー提示

1. 生成したレポートのファイルパスをユーザーに伝える
2. エグゼクティブサマリーの内容を提示する
3. カバレッジが不十分な領域や追加調査の候補があれば提案する
4. ユーザーが追加調査を希望する場合はPhase 3に戻る（Evidence Tableは差分更新される。批判的レビューが有効な場合、再度Phase 6も実行される）
